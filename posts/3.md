---
title: "Benchmarking Web APIs"
date: "2023-07-17"
---
Recently for a service at work, I needed to create an internal web API that is expected to serve requests at a rate of >10k per second. Not to get too much into the details of the implementation, but most of the time (<99%) the API will just get an ID and pull it from some hash map in memory. Since this seems pretty simple I decided to benchmark some languages and their respective frameworks and see what will give me the best bang for my buck.

To do this benchmark I've decided to use the open-source tool *Vegeta*, it's pretty simple to set up and use. The few commands to get it up and running are:
```sh
echo '{"account_id": "123456789"}' > request.json
echo 'POST http://my/api/path
Content-Type: application/json
@request.json' > goku
```
And then using this command:
```sh
vegeta attack -targets=goku -rate=0 -max-workers=30 -duration=10s | vegeta report --type=json | python -m json.tool
```
The service was hosted on AWS's ECS on a small 1 CPU 1GB RAM pod.

My first test was with Rust and Axum. Rust's Redis crate is still not mature enough and missing some key features for the rest of the service's needs, but I decided to check its performance for fun. Surprisingly, it didn't do as well as I'd imagined. Maybe I messed something up in the implementation, but I didn't want to delve too much into it since it won't be used regardless.

```json
{
    "bytes_in": {
        "mean": 954,
        "total": 141388524
    },
    "bytes_out": {
        "mean": 55,
        "total": 8151330
    },
    "duration": 9999925711,
    "errors": [],
    "latencies": {
        "50th": 1729779,
        "95th": 5048208,
        "99th": 8941265,
        "max": 31829423,
        "mean": 1927425,
        "total": 285655957167
    },
    "rate": 14820.710101573275,
    "requests": 148206,
    "status_codes": {
        "200": 148206
    },
    "success": 1,
    "throughput": 14816.129717345233,
    "wait": 3091462
}
```

So roughly 15k requests per second was my baseline using Rust. I was a bit disappointed, but no matter. Since Python comes pretty naturally to me, I decided to test it out next. I was using Robyn since I figured I could get a boost of performance from the Rust backend. The results were unsurprisingly worse than Rust:

```json
{
    "bytes_in": {
        "mean": 533,
        "total": 33141407
    },
    "bytes_out": {
        "mean": 55,
        "total": 3419845
    },
    "duration": 10000225967,
    "errors": [],
    "latencies": {
        "50th": 4529402,
        "95th": 8484596,
        "99th": 10798571,
        "max": 21378090,
        "mean": 4813238,
        "total": 299282364287
    },
    "rate": 6217.759499153925,
    "requests": 62179,
    "status_codes": {
        "200": 62179
    },
    "success": 1,
    "throughput": 6215.201371373432,
    "wait": 4116014
}
```

Well, a smidge above 6k results is not good enough. I was pretty confident in my implementation too, so I decided to check languages that I'm less familiar with, and I started with Node.js and express. I am not sure my code was the most efficient one, but it. seemed simple enough that I'm confident that there isn't a horrendous performance issue there.

```json

    "bytes_in": {
        "mean": 525,
        "total": 19645500
    },
    "bytes_out": {
        "mean": 55,
        "total": 2058100
    },
    "duration": 10000245201,
    "errors": [],
    "latencies": {
        "50th": 6839064,
        "95th": 13490409,
        "99th": 15813326,
        "max": 24272522,
        "mean": 8017988,
        "total": 300033133896
    },
    "rate": 3741.9082480355673,
    "requests": 37420,
    "status_codes": {
        "200": 37420
    },
    "success": 1,
    "throughput": 3738.2381190201722,
    "wait": 9818045
}
```

This is absolutely atrocious. I always was under the assumption that Node.js is better than Python for this kind of task, but not even 4k requests per second is very low. I am assuming Python did well due to Robyn, but still, Node.js is not the way to go. Lastly, I decided to check Go. I am even less familiar with Go than I am with Node.js, but I tried to make it work using Gin, which I found was very ergonomic.
```json
{
    "bytes_in": {
        "mean": 521,
        "total": 96250582
    },
    "bytes_out": {
        "mean": 56,
        "total": 10345552
    },
    "duration": 9999993285,
    "errors": [],
    "latencies": {
        "50th": 1496650,
        "95th": 2866803,
        "99th": 7441136,
        "max": 378002274,
        "mean": 1528978,
        "total": 282466608934
    },
    "rate": 18474.21240543363,
    "requests": 184742,
    "status_codes": {
        "200": 184742
    },
    "success": 1,
    "throughput": 18471.322930753024,
    "wait": 1564302
}
```

Wow! 18k requests per second is very impressive, it has even outdone my initial Rust implementation. This made me pretty sure that whatever I did in Rust, I probably messed something up, but no matter. This looks like a clear winner since its Redis package has the support to all the features I needed.

Going with Go was never my first instinct, but this benchmark exercise really helped me experiment with the different stacks, and see how easy or how hard it is to make the same thing work in each language. And eventually find the best solution for my product's needs!

Hope you found this useful as well, and feel free to reach out to me if you did or if you think I did something horribly wrong.

-- Ido
